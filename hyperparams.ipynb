{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройка окружения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.local/lib/python3.10/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/mle-user/.local/lib/python3.10/site-packages/pydantic/_internal/_config.py:321: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "import os\n",
    "import psycopg\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE_NAME = 'users_churn'\n",
    "\n",
    "TRACKING_SERVER_HOST = '127.0.0.1'\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "EXPERIMENT_NAME = 'churn_task_alexdem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials postgres\n",
    "\n",
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": os.getenv(\"DB_DESTINATION_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_DESTINATION_PORT\"),\n",
    "    \"dbname\": os.getenv(\"DB_DESTINATION_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_DESTINATION_USER\"),\n",
    "    \"password\": os.getenv(\"DB_DESTINATION_PASSWORD\"),\n",
    "}\n",
    "\n",
    "connection.update(postgres_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow settings\n",
    "\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "mlflow.set_registry_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>begin_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>type</th>\n",
       "      <th>paperless_billing</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>internet_service</th>\n",
       "      <th>...</th>\n",
       "      <th>device_protection</th>\n",
       "      <th>tech_support</th>\n",
       "      <th>streaming_tv</th>\n",
       "      <th>gender</th>\n",
       "      <th>streaming_movies</th>\n",
       "      <th>senior_citizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>multiple_lines</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>DSL</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>DSL</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id customer_id begin_date end_date            type paperless_billing  \\\n",
       "0   1  7590-VHVEG 2020-01-01      NaT  Month-to-month               Yes   \n",
       "1   2  5575-GNVDE 2017-04-01      NaT        One year                No   \n",
       "\n",
       "     payment_method  monthly_charges  total_charges internet_service  ...  \\\n",
       "0  Electronic check            29.85          29.85              DSL  ...   \n",
       "1      Mailed check            56.95        1889.50              DSL  ...   \n",
       "\n",
       "  device_protection tech_support streaming_tv  gender streaming_movies  \\\n",
       "0                No           No           No  Female               No   \n",
       "1               Yes           No           No    Male               No   \n",
       "\n",
       "  senior_citizen partner  dependents multiple_lines target  \n",
       "0              0     Yes          No           None      0  \n",
       "1              0      No          No             No      0  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выгрузка данных\n",
    "\n",
    "with psycopg.connect(**connection) as conn:\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "        data = cur.fetchall()\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "df.head(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 24.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# обработка признаков ранее обученным трансформером\n",
    "\n",
    "cat_features = [\n",
    "    'paperless_billing',\n",
    "    'payment_method',\n",
    "    'internet_service',\n",
    "    'online_security',\n",
    "    'online_backup',\n",
    "    'device_protection',\n",
    "    'tech_support',\n",
    "    'streaming_tv',\n",
    "    'streaming_movies',\n",
    "    'gender',\n",
    "    'senior_citizen',\n",
    "    'partner',\n",
    "    'dependents',\n",
    "    'multiple_lines',\n",
    "    'type'\n",
    "]\n",
    "num_features = [\"monthly_charges\", \"total_charges\"]\n",
    "target = ['target'] # колонка с таргетом вашей модели\n",
    "df[num_features] = df[num_features].fillna(0)\n",
    "\n",
    "df['senior_citizen'] = df['senior_citizen'].map({1:'Yes', 0:'No'})\n",
    "\n",
    "logged_transformer = 'runs:/01e47211b28c4a6cbc96fc7f9302b453/column_transformer'\n",
    "\n",
    "# Load model\n",
    "logged_transformer = mlflow.sklearn.load_model(logged_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"monthly_charges\", \"total_charges\", \"senior_citizen\"]\n",
    "target = \"target\"\n",
    "\n",
    "split_column = 'begin_date'\n",
    "stratify_column = target\n",
    "test_size = 0.2\n",
    "\n",
    "df = df.sort_values(by=[split_column])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[cat_features + num_features], df[target], test_size=test_size, shuffle=False)\n",
    "\n",
    "X_train = logged_transformer.transform(X_train)\n",
    "X_test = logged_transformer.transform(X_test)\n",
    "\n",
    "print(f\"Размер выборки для обучения: {X_train.shape}\")\n",
    "print(f\"Размер выборки для теста: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, confusion_matrix, precision_score, recall_score, f1_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = \"Logloss\"\n",
    "task_type = 'CPU'\n",
    "random_seed = 0\n",
    "iterations = 300\n",
    "verbose = False\n",
    "\n",
    "params = {\n",
    "    'depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.9],\n",
    "    'l2_leaf_reg': [1, 5, 20],\n",
    "}\n",
    "\n",
    "model = CatBoostClassifier(loss_function=loss_function, verbose=verbose, task_type=task_type, random_seed=random_seed, iterations=iterations)\n",
    "\n",
    "cv = GridSearchCV(estimator=model, param_grid=params, cv=2, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "clf = cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
      "       'param_depth', 'param_l2_leaf_reg', 'param_learning_rate', 'params',\n",
      "       'split0_test_score', 'split1_test_score', 'mean_test_score',\n",
      "       'std_test_score', 'rank_test_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "\n",
    "best_params = clf.best_params_\n",
    "\n",
    "model_best = CatBoostClassifier(loss_function=loss_function, **best_params, verbose=verbose, task_type=task_type, random_seed=random_seed, iterations=iterations)\n",
    "\n",
    "model_best.fit(X_train, y_train)\n",
    "\n",
    "prediction = model_best.predict(X_test)\n",
    "probas = model_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# расчёт метрик качества\n",
    "metrics = {}\n",
    "\n",
    "_, err1, _, err2 = confusion_matrix(y_test, prediction, normalize='all').ravel()\n",
    "auc = roc_auc_score(y_test, probas)\n",
    "precision = precision_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction)\n",
    "f1 = f1_score(y_test, prediction)\n",
    "logloss = log_loss(y_test, prediction)\n",
    "\n",
    "# сохранение метрик в словарь\n",
    "metrics[\"err1\"] = err1\n",
    "metrics[\"err2\"] = err2\n",
    "metrics[\"auc\"] = auc\n",
    "metrics[\"precision\"] = precision\n",
    "metrics[\"recall\"] = recall\n",
    "metrics[\"f1\"] = f1\n",
    "metrics[\"logloss\"] = logloss\n",
    "\n",
    "print(cv_results.columns)\n",
    "# дополнительные метрики из результатов кросс-валидации\n",
    "metrics[\"mean_fit_time\"] = cv_results['mean_fit_time'].mean()# среднее время обучения\n",
    "metrics[\"std_fit_time\"] =  cv_results['std_fit_time'].mean()# стандартное отклонение времени обучения\n",
    "metrics[\"mean_test_score\"] = cv_results['mean_test_score'].mean()# средний результат на тесте\n",
    "metrics['std_test_score'] = cv_results['std_test_score'].mean()\n",
    "metrics['best_score'] = clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'churn_task_alexndem'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:15: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/mle-user/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "Successfully registered model 'model_churn_grid_search'.\n",
      "2025/06/05 20:32:16 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: model_churn_grid_search, version 1\n",
      "Created version '1' of model 'model_churn_grid_search'.\n"
     ]
    }
   ],
   "source": [
    "RUN_NAME = 'model_grid_search' # ваш код здесь\n",
    "REGISTRY_MODEL_NAME = 'model_churn_grid_search'\n",
    "\n",
    "# настройки для логирования в MLFlow\n",
    "pip_requirements = 'requirements.txt'\n",
    "signature = mlflow.models.infer_signature(X_test, prediction)\n",
    "input_example = X_test[:10]\n",
    "\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    cv_info = mlflow.sklearn.log_model(cv, artifact_path='cv')\n",
    "    model_info = mlflow.catboost.log_model( \n",
    "\t\t\tcb_model=model_best,\n",
    "            artifact_path=\"models\",\n",
    "            registered_model_name=REGISTRY_MODEL_NAME,\n",
    "            signature=signature,\n",
    "            input_example=input_example,\n",
    "            pip_requirements=pip_requirements)\n",
    "\t\t\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.log_params(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = \"Logloss\"\n",
    "task_type = 'CPU'\n",
    "random_seed = 0\n",
    "iterations = 300\n",
    "verbose = False\n",
    "\n",
    "param_distributions = {\n",
    "    'depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.9],\n",
    "    'l2_leaf_reg': [1, 5, 20],\n",
    "}\n",
    "\n",
    "model = CatBoostClassifier(loss_function=loss_function, verbose=verbose, task_type=task_type, random_seed=random_seed, iterations=iterations)\n",
    "\n",
    "cv = RandomizedSearchCV(estimator=model, param_distributions=param_distributions, n_iter=20, cv=2, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "clf = cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "\n",
    "best_params = clf.best_params_\n",
    "\n",
    "model = CatBoostClassifier(loss_function=loss_function, **best_params, verbose=verbose, task_type=task_type, random_seed=random_seed, iterations=iterations)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "probas = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# расчёт метрик качества\n",
    "metrics = {}\n",
    "\n",
    "_, err1, _, err2 = confusion_matrix(y_test, prediction, normalize='all').ravel()\n",
    "auc = roc_auc_score(y_test, probas)\n",
    "precision = precision_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction)\n",
    "f1 = f1_score(y_test, prediction)\n",
    "logloss = log_loss(y_test, prediction)\n",
    "\n",
    "# сохранение метрик в словарь\n",
    "metrics[\"err1\"] = err1\n",
    "metrics[\"err2\"] = err2\n",
    "metrics[\"auc\"] = auc\n",
    "metrics[\"precision\"] = precision\n",
    "metrics[\"recall\"] = recall\n",
    "metrics[\"f1\"] = f1\n",
    "metrics[\"logloss\"] = logloss\n",
    "\n",
    "# дополнительные метрики из результатов кросс-валидации\n",
    "metrics[\"mean_fit_time\"] = cv_results['mean_fit_time'].mean()# среднее время обучения\n",
    "metrics[\"std_fit_time\"] =  cv_results['std_fit_time'].mean()# стандартное отклонение времени обучения\n",
    "metrics[\"mean_test_score\"] = cv_results['mean_test_score'].mean()# средний результат на тесте\n",
    "metrics['std_test_score'] = cv_results['std_test_score'].mean()\n",
    "metrics['best_score'] = clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:15: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/mle-user/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "Successfully registered model 'model_churn_random_search'.\n",
      "2025/06/05 20:35:24 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: model_churn_random_search, version 1\n",
      "Created version '1' of model 'model_churn_random_search'.\n"
     ]
    }
   ],
   "source": [
    "RUN_NAME = 'model_random_search' # ваш код здесь\n",
    "REGISTRY_MODEL_NAME = 'model_churn_random_search'\n",
    "\n",
    "# настройки для логирования в MLFlow\n",
    "pip_requirements = 'requirements.txt'\n",
    "signature = mlflow.models.infer_signature(X_test, prediction)\n",
    "input_example = X_test[:10]\n",
    "\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    cv_info = mlflow.sklearn.log_model(cv, artifact_path='cv')\n",
    "    model_info = mlflow.catboost.log_model( \n",
    "\t\t\tcb_model=model_best,\n",
    "            artifact_path=\"models\",\n",
    "            registered_model_name=REGISTRY_MODEL_NAME,\n",
    "            signature=signature,\n",
    "            input_example=input_example,\n",
    "            pip_requirements=pip_requirements)\n",
    "\t\t\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.log_params(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
