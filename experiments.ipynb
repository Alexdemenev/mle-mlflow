{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.local/lib/python3.10/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/mle-user/.local/lib/python3.10/site-packages/pydantic/_internal/_config.py:321: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# делаем import необходимых библиотек\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install psycopg\n",
    "# !{sys.executable} -m pip install 'psycopg[binary]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск с локальной записью артефактов и метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.local/lib/python3.10/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/mle-user/.local/lib/python3.10/site-packages/pydantic/_internal/_config.py:321: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run id запуска: a874309545674637a6f48c6858ff8a7c\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# устанавливаем локальное хранилище для наших экспериментов\n",
    "# хранилище должно быть такое же, как и при запуске сервиса\n",
    "mlflow.set_tracking_uri('file:./mlflow_experiments_store')\n",
    "\n",
    "# получаем id эксеримента, который создаётся по умолчанию\n",
    "# эксперимент по умолчанию называется Default\n",
    "experiment_id = mlflow.get_experiment_by_name(\"Default\").experiment_id\n",
    "\n",
    "# залогируем тестовую метрику и артефакт\n",
    "with mlflow.start_run(run_name='Default', experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    mlflow.log_metric(\"test_metric\", 0)\n",
    "    mlflow.log_artifact(\"test_artifact.txt\", \"test_artifact\")\n",
    "\n",
    "print(f\"Run id запуска: {run_id}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_metric\n"
     ]
    }
   ],
   "source": [
    "!ls mlflow_experiments_store/0/{run_id}/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_artifact"
     ]
    }
   ],
   "source": [
    "!cat mlflow_experiments_store/0/{run_id}/artifacts/test_artifact/test_artifact.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск с БД sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('http://0.0.0.0:5000')\n",
    "\n",
    "# получаем id эксперимента, который создаётся по умолчанию\n",
    "# эксперимент по умолчанию называется Default\n",
    "experiment_id = mlflow.get_experiment_by_name(\"Default\").experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=\"Default\", experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    mlflow.log_metric(\"test_metric_sqlite\", 0)\n",
    "    mlflow.log_artifact(\"test_artifact.txt\", \"test_artifact_sqlite\")\n",
    "\n",
    "# проверим, что наши данные сохранились в локальной папке, а также создалась база данных SQLite\n",
    "assert os.path.exists(\"mlflow_experiments_store_sqlite\")\n",
    "assert os.path.exists(\"mydb.sqlite\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск с удаленным хранилищем артефактов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определяем основные credentials, которые нужны для подключения к MLflow\n",
    "# важно, что credentials мы передаём для себя как пользователей Tracking Service\n",
    "# у вас должен быть доступ к бакету, в который вы будете складывать артефакты\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" #endpoint бакета от YandexCloud\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\") # получаем id ключа бакета, к которому подключён MLFlow, из .env\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\") # получаем ключ бакета, к которому подключён MLFlow, из .env\n",
    "\n",
    "# определяем глобальные переменные\n",
    "# поднимаем MLflow локально\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "YOUR_NAME = \"alexdem\" # введите своё имя для создания уникального эксперимента\n",
    "assert YOUR_NAME, \"введите своё имя в переменной YOUR_NAME для создания уникального эксперимента\"\n",
    "\n",
    "# название тестового эксперимента и запуска (run) внутри него\n",
    "EXPERIMENT_NAME = f\"test_connection_experiment_{YOUR_NAME}\"\n",
    "RUN_NAME = \"test_connection_run\"\n",
    "\n",
    "# тестовые данные\n",
    "METRIC_NAME = \"test_metric\"\n",
    "METRIC_VALUE = 0\n",
    "\n",
    "# устанавливаем host, который будет отслеживать наши эксперименты\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "\n",
    "# создаём тестовый эксперимент и записываем в него тестовую информацию\n",
    "experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    mlflow.log_metric(METRIC_NAME, METRIC_VALUE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 4. Проверяем себя, что в MLflow:\n",
    "# - создался `experiment` с нашим именем\n",
    "# - внутри эксперимента появился запуск `run`\n",
    "# - внутри `run` записалась наша тестовая `metric`\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "run = mlflow.get_run(run_id)\n",
    "\n",
    "assert \"active\" == experiment.lifecycle_stage\n",
    "assert mlflow.get_run(run_id)\n",
    "assert METRIC_VALUE == run.data.metrics[METRIC_NAME] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выгрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер нашей таблицы: 7043 строк; 22 столбцов\n"
     ]
    }
   ],
   "source": [
    "import psycopg2 as psycopg\n",
    "import pandas as pd\n",
    "\n",
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": os.getenv(\"DB_DESTINATION_HOST\"), \n",
    "    \"port\": \"6432\",\n",
    "    \"dbname\": os.getenv(\"DB_DESTINATION_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_DESTINATION_USER\"),\n",
    "    \"password\": os.getenv(\"DB_DESTINATION_PASSWORD\"),\n",
    "}\n",
    "assert all([var_value != \"\" for var_value in list(postgres_credentials.values())])\n",
    "\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "# определяем название таблицы, в которой хранятся наши данные\n",
    "TABLE_NAME = \"users_churn\"\n",
    "\n",
    "\n",
    "# эта конструкция создаёт контекстное управление для соединения с базой данных \n",
    "# оператор with гарантирует, что соединение будет корректно закрыто после выполнения всех операций с базой данных\n",
    "# причём закрыто оно будет даже в случае ошибки при работе с базой данных\n",
    "# это нужно, чтобы не допустить так называемую \"утечку памяти\"\n",
    "with psycopg.connect(**connection) as conn:\n",
    "\n",
    "# создаём объект курсора для выполнения запросов к базе данных \n",
    "# с помощью метода execute() выполняется SQL-запрос для выборки данных из таблицы TABLE_NAME\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "\t\t\t\t\n",
    "\t\t\t\t# извлекаем все строки, полученные в результате выполнения запроса\n",
    "        data = cur.fetchall()\n",
    "\n",
    "\t\t\t\t# получаем список имён столбцов из объекта курсора\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "# создаём объект DataFrame из полученных данных и имён столбцов \n",
    "# это позволяет удобно работать с данными в Python с использованием библиотеки Pandas\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "print(f\"Размер нашей таблицы: {df.shape[0]} строк; {df.shape[1]} столбцов\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определяем основные credentials, которые нужны для подключения к MLflow\n",
    "# важно, что credentials мы передаём для себя как пользователей Tracking Service\n",
    "# у вас должен быть доступ к бакету, в который вы будете складывать артефакты\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" #endpoint бакета от YandexCloud\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\") # получаем id ключа бакета, к которому подключён MLFlow, из .env\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\") # получаем ключ бакета, к которому подключён MLFlow, из .env\n",
    "\n",
    "# определяем глобальные переменные\n",
    "# поднимаем MLflow локально\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# устанавливаем host, который будет отслеживать наши эксперименты\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"churn_task_alexdem\"\n",
    "RUN_NAME = \"data_check\"\n",
    "\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if experiment_id is None:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "else:\n",
    "    experiment_id = experiment_id.experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {\"mae\": 2, \"r2\": 0.82}\n",
    "artifact_path = \"dataframe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"columns.txt\", \"w\") as f:\n",
    "    f.write(\",\".join(df.columns))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"users_churn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RUN_NAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(run_name\u001b[38;5;241m=\u001b[39m\u001b[43mRUN_NAME\u001b[49m, experiment_id\u001b[38;5;241m=\u001b[39mexperiment_id) \u001b[38;5;28;01mas\u001b[39;00m run:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# получаем уникальный идентификатор запуска эксперимента\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     run_id \u001b[38;5;241m=\u001b[39m run\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# логируем метрики эксперимента\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# предполагается, что переменная stats содержит словарь с метриками,\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# где ключи — это названия метрик, а значения — числовые значения метрик\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RUN_NAME' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    # получаем уникальный идентификатор запуска эксперимента\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # логируем метрики эксперимента\n",
    "    # предполагается, что переменная stats содержит словарь с метриками,\n",
    "    # где ключи — это названия метрик, а значения — числовые значения метрик\n",
    "    mlflow.log_metrics(stats)\n",
    "    \n",
    "    # логируем файлы как артефакты эксперимента — 'columns.txt' и 'users_churn.csv'\n",
    "    mlflow.log_artifact(\"columns.txt\", artifact_path)\n",
    "    mlflow.log_artifact(\"users_churn.csv\", artifact_path)\n",
    "\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "# получаем данные о запуске эксперимента по его уникальному идентификатору\n",
    "run = mlflow.get_run(run_id)\n",
    "\n",
    "\n",
    "# проверяем, что статус запуска эксперимента изменён на 'FINISHED'\n",
    "# это утверждение (assert) можно использовать для автоматической проверки того, \n",
    "# что эксперимент был завершён успешно\n",
    "assert run.info.status == \"FINISHED\"\n",
    "\n",
    "# удаляем файлы 'columns.txt' и 'users_churn.csv' из файловой системы,\n",
    "# чтобы очистить рабочую среду после логирования артефактов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логирование метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, confusion_matrix, precision_score, recall_score, f1_score, log_loss\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                            int64\n",
       "customer_id                  object\n",
       "begin_date           datetime64[ns]\n",
       "end_date             datetime64[ns]\n",
       "type                         object\n",
       "paperless_billing            object\n",
       "payment_method               object\n",
       "monthly_charges             float64\n",
       "total_charges               float64\n",
       "internet_service             object\n",
       "online_security              object\n",
       "online_backup                object\n",
       "device_protection            object\n",
       "tech_support                 object\n",
       "streaming_tv                 object\n",
       "gender                       object\n",
       "streaming_movies             object\n",
       "senior_citizen                int64\n",
       "partner                      object\n",
       "dependents                   object\n",
       "multiple_lines               object\n",
       "target                        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    5174\n",
       "1    1869\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_active'] = df['end_date'] == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = df.drop(columns=['end_date']).dtypes[df.dtypes == 'object'].index.tolist()\n",
    "drop_features = df.dtypes[df.dtypes == 'datetime64[ns]'].index.tolist() + ['end_date']\n",
    "target = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_charges'] = df['total_charges'].fillna(0)\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=target + drop_features), df[target], test_size=0.2, random_state=42)\n",
    "\n",
    "model = CatBoostClassifier(iterations=300, cat_features=cat_features, verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "proba = model.predict_proba(X_test)[:, 1]\n",
    "prediction = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[920, 108],\n",
       "       [160, 221]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, err1, _, err2 = confusion_matrix(y_test, prediction).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_test, proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65294535, 0.07665011, 0.11355571, 0.15684883])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, prediction, normalize='all').ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([920, 108, 160, 221])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, prediction).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multiple_lines\n",
       "No     2679\n",
       "Yes    2399\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['multiple_lines'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logloss = log_loss(y_test, proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_features:\n",
    "    X_test[col] = X_test[col].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     int64\n",
       "customer_id           object\n",
       "type                  object\n",
       "paperless_billing     object\n",
       "payment_method        object\n",
       "monthly_charges      float64\n",
       "total_charges        float64\n",
       "internet_service      object\n",
       "online_security       object\n",
       "online_backup         object\n",
       "device_protection     object\n",
       "tech_support          object\n",
       "streaming_tv          object\n",
       "gender                object\n",
       "streaming_movies      object\n",
       "senior_citizen         int64\n",
       "partner               object\n",
       "dependents            object\n",
       "multiple_lines        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'churn_model_alexdem' already exists. Creating a new version of this model...\n",
      "2025/05/30 19:44:01 INFO mlflow.tracking._model_registry.client: Waiting up to 60 seconds for model version to finish creation. Model name: churn_model_alexdem, version 2\n",
      "Created version '2' of model 'churn_model_alexdem'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import mlflow\n",
    "\n",
    "\n",
    "EXPERIMENT_NAME = \"churn_task_alexdem\"\n",
    "RUN_NAME = \"model_0_registry\"\n",
    "REGISTRY_MODEL_NAME = \"churn_model_alexdem\"\n",
    "\n",
    "\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "\n",
    "pip_requirements = \"./requirements.txt\"\n",
    "signature = mlflow.models.infer_signature(X_test.values, prediction)\n",
    "input_example = X_test[:10]\n",
    "metadata = {'model_type': 'monthly'}\n",
    "\n",
    "\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    model_info = mlflow.catboost.log_model( \n",
    "\t\t\tcb_model=model,\n",
    "            artifact_path=\"models\",\n",
    "            registered_model_name=REGISTRY_MODEL_NAME,\n",
    "            pip_requirements=pip_requirements,\n",
    "            signature=signature,\n",
    "            input_example=input_example,\n",
    "            metadata=metadata,\n",
    "            await_registration_for=60\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlflow.catboost.load_model(model_uri=model_info.model_uri)\n",
    "model_predictions = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логирование другой версии модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "mlflow.set_registry_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_test, proba)\n",
    "logloss = log_loss(y_test, proba)\n",
    "_, err1, _, err2 = confusion_matrix(y_test, prediction).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:15: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/mle-user/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "Registered model 'churn_model_alexdem' already exists. Creating a new version of this model...\n",
      "2025/06/01 15:48:00 INFO mlflow.tracking._model_registry.client: Waiting up to 60 seconds for model version to finish creation. Model name: churn_model_alexdem, version 4\n",
      "Created version '4' of model 'churn_model_alexdem'.\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = \"churn_task_alexdem\"\n",
    "RUN_NAME = \"model_0_registry\"\n",
    "REGISTRY_MODEL_NAME = \"churn_model_alexdem\"\n",
    "\n",
    "pip_requirements= \"./requirements.txt\"\n",
    "signature = mlflow.models.infer_signature(X_test.values, prediction)\n",
    "input_example = X_test[:10]\n",
    "metadata = {'model_type': 'monthly'}\n",
    "\n",
    "\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    model_info = mlflow.catboost.log_model( \n",
    "\t\t\tcb_model=model,\n",
    "            artifact_path=\"models\",\n",
    "            registered_model_name=REGISTRY_MODEL_NAME,\n",
    "            pip_requirements=pip_requirements,\n",
    "            signature=signature,\n",
    "            input_example=input_example,\n",
    "            metadata=metadata,\n",
    "            await_registration_for=60\n",
    "\t\t)\n",
    "    mlflow.log_metrics({'auc': auc, 'logloss': logloss, 'err1': err1, 'err2': err2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model info:\n",
      " [<ModelVersion: aliases=[], creation_timestamp=1748792880355, current_stage='None', description='', last_updated_timestamp=1748792880355, name='churn_model_alexdem', run_id='06b7771931c14c828a881f9591c00430', run_link='', source='s3://s3-student-mle-20250329-2e5319257f/2/06b7771931c14c828a881f9591c00430/artifacts/models', status='READY', status_message='', tags={}, user_id='', version='4'>, <ModelVersion: aliases=[], creation_timestamp=1748792731629, current_stage='None', description='', last_updated_timestamp=1748792731629, name='churn_model_alexdem', run_id='d0a545e1cf7d4e6ab55a3cc3af33eea5', run_link='', source='s3://s3-student-mle-20250329-2e5319257f/2/d0a545e1cf7d4e6ab55a3cc3af33eea5/artifacts/models', status='READY', status_message='', tags={}, user_id='', version='3'>, <ModelVersion: aliases=[], creation_timestamp=1748634241316, current_stage='Production', description='', last_updated_timestamp=1748634558267, name='churn_model_alexdem', run_id='30f13eac4e054f0ba05df06bb0aad9f9', run_link='', source='s3://s3-student-mle-20250329-2e5319257f/2/30f13eac4e054f0ba05df06bb0aad9f9/artifacts/models', status='READY', status_message='', tags={}, user_id='', version='2'>, <ModelVersion: aliases=[], creation_timestamp=1748632867465, current_stage='Staging', description='', last_updated_timestamp=1748633454424, name='churn_model_alexdem', run_id='e8e5422a93dd45a7871cf26f92b3eeff', run_link='', source='s3://s3-student-mle-20250329-2e5319257f/2/e8e5422a93dd45a7871cf26f92b3eeff/artifacts/models', status='READY', status_message='', tags={}, user_id='', version='1'>]\n"
     ]
    }
   ],
   "source": [
    "client = mlflow.MlflowClient()\n",
    "\n",
    "\n",
    "models = client.search_model_versions(\n",
    "    filter_string=f\"name = '{REGISTRY_MODEL_NAME}'\"\n",
    ")\n",
    "print(f\"Model info:\\n {models}\")\n",
    "\n",
    "model_name_1 = models[-1].name\n",
    "model_version_1 = models[-1].version\n",
    "model_stage_1 = models[-1].current_stage\n",
    "\n",
    "model_name_2 = models[-2].name\n",
    "model_version_2 = models[-2].version\n",
    "model_stage_2 = models[-2].current_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1748792731629, current_stage='Production', description='', last_updated_timestamp=1748793204118, name='churn_model_alexdem', run_id='d0a545e1cf7d4e6ab55a3cc3af33eea5', run_link='', source='s3://s3-student-mle-20250329-2e5319257f/2/d0a545e1cf7d4e6ab55a3cc3af33eea5/artifacts/models', status='READY', status_message='', tags={}, user_id='', version='3'>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "client.transition_model_version_stage(\n",
    "    name=REGISTRY_MODEL_NAME,\n",
    "    version=4,\n",
    "    stage=\"Staging\"\n",
    ")\n",
    "client.transition_model_version_stage(\n",
    "    name=REGISTRY_MODEL_NAME,\n",
    "    version=3,\n",
    "    stage=\"Production\"\n",
    ")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.rename_registered_model(\n",
    "    name=REGISTRY_MODEL_NAME,\n",
    "    new_name=REGISTRY_MODEL_NAME+\"_b2c\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
