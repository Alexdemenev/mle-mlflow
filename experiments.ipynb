{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.local/lib/python3.10/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/mle-user/.local/lib/python3.10/site-packages/pydantic/_internal/_config.py:321: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# делаем import необходимых библиотек\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install psycopg\n",
    "# !{sys.executable} -m pip install 'psycopg[binary]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск с локальной записью артефактов и метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.local/lib/python3.10/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/mle-user/.local/lib/python3.10/site-packages/pydantic/_internal/_config.py:321: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run id запуска: a874309545674637a6f48c6858ff8a7c\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# устанавливаем локальное хранилище для наших экспериментов\n",
    "# хранилище должно быть такое же, как и при запуске сервиса\n",
    "mlflow.set_tracking_uri('file:./mlflow_experiments_store')\n",
    "\n",
    "# получаем id эксеримента, который создаётся по умолчанию\n",
    "# эксперимент по умолчанию называется Default\n",
    "experiment_id = mlflow.get_experiment_by_name(\"Default\").experiment_id\n",
    "\n",
    "# залогируем тестовую метрику и артефакт\n",
    "with mlflow.start_run(run_name='Default', experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    mlflow.log_metric(\"test_metric\", 0)\n",
    "    mlflow.log_artifact(\"test_artifact.txt\", \"test_artifact\")\n",
    "\n",
    "print(f\"Run id запуска: {run_id}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_metric\n"
     ]
    }
   ],
   "source": [
    "!ls mlflow_experiments_store/0/{run_id}/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_artifact"
     ]
    }
   ],
   "source": [
    "!cat mlflow_experiments_store/0/{run_id}/artifacts/test_artifact/test_artifact.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск с БД sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('http://0.0.0.0:5000')\n",
    "\n",
    "# получаем id эксперимента, который создаётся по умолчанию\n",
    "# эксперимент по умолчанию называется Default\n",
    "experiment_id = mlflow.get_experiment_by_name(\"Default\").experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=\"Default\", experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    mlflow.log_metric(\"test_metric_sqlite\", 0)\n",
    "    mlflow.log_artifact(\"test_artifact.txt\", \"test_artifact_sqlite\")\n",
    "\n",
    "# проверим, что наши данные сохранились в локальной папке, а также создалась база данных SQLite\n",
    "assert os.path.exists(\"mlflow_experiments_store_sqlite\")\n",
    "assert os.path.exists(\"mydb.sqlite\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск с удаленным хранилищем артефактов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определяем основные credentials, которые нужны для подключения к MLflow\n",
    "# важно, что credentials мы передаём для себя как пользователей Tracking Service\n",
    "# у вас должен быть доступ к бакету, в который вы будете складывать артефакты\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" #endpoint бакета от YandexCloud\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\") # получаем id ключа бакета, к которому подключён MLFlow, из .env\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\") # получаем ключ бакета, к которому подключён MLFlow, из .env\n",
    "\n",
    "# определяем глобальные переменные\n",
    "# поднимаем MLflow локально\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "YOUR_NAME = \"alexdem\" # введите своё имя для создания уникального эксперимента\n",
    "assert YOUR_NAME, \"введите своё имя в переменной YOUR_NAME для создания уникального эксперимента\"\n",
    "\n",
    "# название тестового эксперимента и запуска (run) внутри него\n",
    "EXPERIMENT_NAME = f\"test_connection_experiment_{YOUR_NAME}\"\n",
    "RUN_NAME = \"test_connection_run\"\n",
    "\n",
    "# тестовые данные\n",
    "METRIC_NAME = \"test_metric\"\n",
    "METRIC_VALUE = 0\n",
    "\n",
    "# устанавливаем host, который будет отслеживать наши эксперименты\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "\n",
    "# создаём тестовый эксперимент и записываем в него тестовую информацию\n",
    "experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    mlflow.log_metric(METRIC_NAME, METRIC_VALUE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 4. Проверяем себя, что в MLflow:\n",
    "# - создался `experiment` с нашим именем\n",
    "# - внутри эксперимента появился запуск `run`\n",
    "# - внутри `run` записалась наша тестовая `metric`\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "run = mlflow.get_run(run_id)\n",
    "\n",
    "assert \"active\" == experiment.lifecycle_stage\n",
    "assert mlflow.get_run(run_id)\n",
    "assert METRIC_VALUE == run.data.metrics[METRIC_NAME] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выгрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер нашей таблицы: 7043 строк; 22 столбцов\n"
     ]
    }
   ],
   "source": [
    "import psycopg2 as psycopg\n",
    "import pandas as pd\n",
    "\n",
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": os.getenv(\"DB_DESTINATION_HOST\"), \n",
    "    \"port\": \"6432\",\n",
    "    \"dbname\": os.getenv(\"DB_DESTINATION_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_DESTINATION_USER\"),\n",
    "    \"password\": os.getenv(\"DB_DESTINATION_PASSWORD\"),\n",
    "}\n",
    "assert all([var_value != \"\" for var_value in list(postgres_credentials.values())])\n",
    "\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "# определяем название таблицы, в которой хранятся наши данные\n",
    "TABLE_NAME = \"users_churn\"\n",
    "\n",
    "\n",
    "# эта конструкция создаёт контекстное управление для соединения с базой данных \n",
    "# оператор with гарантирует, что соединение будет корректно закрыто после выполнения всех операций с базой данных\n",
    "# причём закрыто оно будет даже в случае ошибки при работе с базой данных\n",
    "# это нужно, чтобы не допустить так называемую \"утечку памяти\"\n",
    "with psycopg.connect(**connection) as conn:\n",
    "\n",
    "# создаём объект курсора для выполнения запросов к базе данных \n",
    "# с помощью метода execute() выполняется SQL-запрос для выборки данных из таблицы TABLE_NAME\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "\t\t\t\t\n",
    "\t\t\t\t# извлекаем все строки, полученные в результате выполнения запроса\n",
    "        data = cur.fetchall()\n",
    "\n",
    "\t\t\t\t# получаем список имён столбцов из объекта курсора\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "# создаём объект DataFrame из полученных данных и имён столбцов \n",
    "# это позволяет удобно работать с данными в Python с использованием библиотеки Pandas\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "print(f\"Размер нашей таблицы: {df.shape[0]} строк; {df.shape[1]} столбцов\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определяем основные credentials, которые нужны для подключения к MLflow\n",
    "# важно, что credentials мы передаём для себя как пользователей Tracking Service\n",
    "# у вас должен быть доступ к бакету, в который вы будете складывать артефакты\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" #endpoint бакета от YandexCloud\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\") # получаем id ключа бакета, к которому подключён MLFlow, из .env\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\") # получаем ключ бакета, к которому подключён MLFlow, из .env\n",
    "\n",
    "# определяем глобальные переменные\n",
    "# поднимаем MLflow локально\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"churn_task_alexdem\"\n",
    "RUN_NAME = \"data_check\"\n",
    "\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {\"mae\": 2, \"r2\": 0.82}\n",
    "artifact_path = \"dataframe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"columns.txt\", \"w\") as f:\n",
    "    f.write(\",\".join(df.columns))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"users_churn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'experiment_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m RUN_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_check\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# создаём новый эксперимент в MLflow с указанным названием \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# если эксперимент с таким именем уже существует, \u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# MLflow возвращает идентификатор существующего эксперимента\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEXPERIMENT_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment_id\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_id:\n\u001b[1;32m     11\u001b[0m     experiment_id \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mcreate_experiment(EXPERIMENT_NAME) \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'experiment_id'"
     ]
    }
   ],
   "source": [
    "# задаём название эксперимента и имя запуска для логирования в MLflow\n",
    "\n",
    "EXPERIMENT_NAME = \"churn_task_alexdem\"\n",
    "RUN_NAME = \"data_check\"\n",
    "\n",
    "# создаём новый эксперимент в MLflow с указанным названием \n",
    "# если эксперимент с таким именем уже существует, \n",
    "# MLflow возвращает идентификатор существующего эксперимента\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "if not experiment_id:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME) \n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    # получаем уникальный идентификатор запуска эксперимента\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # логируем метрики эксперимента\n",
    "    # предполагается, что переменная stats содержит словарь с метриками,\n",
    "    # где ключи — это названия метрик, а значения — числовые значения метрик\n",
    "    mlflow.log_metrics(stats)\n",
    "    \n",
    "    # логируем файлы как артефакты эксперимента — 'columns.txt' и 'users_churn.csv'\n",
    "    mlflow.log_artifact(\"columns.txt\", artifact_path)\n",
    "    mlflow.log_artifact(\"users_churn.csv\", artifact_path)\n",
    "\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "# получаем данные о запуске эксперимента по его уникальному идентификатору\n",
    "run = mlflow.get_run(run_id)\n",
    "\n",
    "\n",
    "# проверяем, что статус запуска эксперимента изменён на 'FINISHED'\n",
    "# это утверждение (assert) можно использовать для автоматической проверки того, \n",
    "# что эксперимент был завершён успешно\n",
    "assert run.info.status == \"FINISHED\"\n",
    "\n",
    "# удаляем файлы 'columns.txt' и 'users_churn.csv' из файловой системы,\n",
    "# чтобы очистить рабочую среду после логирования артефактов\n",
    "os.remove(\"columns.txt\")\n",
    "os.remove(\"users_churn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логирование метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, confusion_matrix, precision_score, recall_score, f1_score, log_loss\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                            int64\n",
       "customer_id                  object\n",
       "begin_date           datetime64[ns]\n",
       "end_date             datetime64[ns]\n",
       "type                         object\n",
       "paperless_billing            object\n",
       "payment_method               object\n",
       "monthly_charges             float64\n",
       "total_charges               float64\n",
       "internet_service             object\n",
       "online_security              object\n",
       "online_backup                object\n",
       "device_protection            object\n",
       "tech_support                 object\n",
       "streaming_tv                 object\n",
       "gender                       object\n",
       "streaming_movies             object\n",
       "senior_citizen                int64\n",
       "partner                      object\n",
       "dependents                   object\n",
       "multiple_lines               object\n",
       "target                        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    5174\n",
       "1    1869\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = df.dtypes[df.dtypes == 'object'].index.tolist()\n",
    "drop_features = df.dtypes[df.dtypes == 'datetime64[ns]'].index.tolist()\n",
    "target = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5613/2028866595.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  df.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['total_charges'] = df['total_charges'].fillna(0)\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=target + drop_features), df[target], test_size=0.2, random_state=42)\n",
    "\n",
    "model = CatBoostClassifier(cat_features=cat_features, verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "proba = model.predict_proba(X_test)[:, 1]\n",
    "prediction = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[920, 108],\n",
       "       [160, 221]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, err1, _, err2 = confusion_matrix(y_test, prediction).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_test, proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8648293963254594"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err2 - fn\n",
    "err1 - fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65294535, 0.07665011, 0.11355571, 0.15684883])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, prediction, normalize='all').ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([920, 108, 160, 221])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, prediction).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multiple_lines\n",
       "No     2679\n",
       "Yes    2399\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['multiple_lines'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logloss = log_loss(y_test, proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_features:\n",
    "    X_test[col] = X_test[col].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     int64\n",
       "customer_id           object\n",
       "type                  object\n",
       "paperless_billing     object\n",
       "payment_method        object\n",
       "monthly_charges      float64\n",
       "total_charges        float64\n",
       "internet_service      object\n",
       "online_security       object\n",
       "online_backup         object\n",
       "device_protection     object\n",
       "tech_support          object\n",
       "streaming_tv          object\n",
       "gender                object\n",
       "streaming_movies      object\n",
       "senior_citizen         int64\n",
       "partner               object\n",
       "dependents            object\n",
       "multiple_lines        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.local/lib/python3.10/site-packages/mlflow/models/signature.py:212: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  inputs = _infer_schema(model_input) if model_input is not None else None\n",
      "Successfully registered model 'churn_model_alexdem'.\n",
      "2025/05/28 20:53:51 INFO mlflow.tracking._model_registry.client: Waiting up to 60 seconds for model version to finish creation. Model name: churn_model_alexdem, version 1\n",
      "Created version '1' of model 'churn_model_alexdem'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import mlflow\n",
    "\n",
    "\n",
    "EXPERIMENT_NAME = \"churn_task_alexdem\"\n",
    "RUN_NAME = \"model_0_registry\"\n",
    "REGISTRY_MODEL_NAME = \"churn_model_alexdem\"\n",
    "\n",
    "\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "\n",
    "pip_requirements = \"requirements.txt\"\n",
    "signature = mlflow.models.infer_signature(X_test, prediction)\n",
    "input_example = input_example = X_test[:10]\n",
    "metadata = {'model_type': 'monthly'}\n",
    "\n",
    "\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    model_info = mlflow.catboost.log_model( \n",
    "\t\t\tcb_model=model,\n",
    "            artifact_path=\"models\",\n",
    "            registered_model_name=REGISTRY_MODEL_NAME,\n",
    "            pip_requirements=pip_requirements,\n",
    "            signature=signature,\n",
    "            input_example=input_example,\n",
    "            metadata=metadata,\n",
    "            await_registration_for=60\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlflow.catboost.load_model(model_uri=model_info.model_uri)\n",
    "model_predictions = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
