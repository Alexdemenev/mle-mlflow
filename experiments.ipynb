{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.local/lib/python3.10/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/mle-user/.local/lib/python3.10/site-packages/pydantic/_internal/_config.py:321: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# делаем import необходимых библиотек\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install psycopg\n",
    "# !{sys.executable} -m pip install 'psycopg[binary]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск с локальной записью артефактов и метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/.local/lib/python3.10/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/mle-user/.local/lib/python3.10/site-packages/pydantic/_internal/_config.py:321: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run id запуска: a874309545674637a6f48c6858ff8a7c\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# устанавливаем локальное хранилище для наших экспериментов\n",
    "# хранилище должно быть такое же, как и при запуске сервиса\n",
    "mlflow.set_tracking_uri('file:./mlflow_experiments_store')\n",
    "\n",
    "# получаем id эксеримента, который создаётся по умолчанию\n",
    "# эксперимент по умолчанию называется Default\n",
    "experiment_id = mlflow.get_experiment_by_name(\"Default\").experiment_id\n",
    "\n",
    "# залогируем тестовую метрику и артефакт\n",
    "with mlflow.start_run(run_name='Default', experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    mlflow.log_metric(\"test_metric\", 0)\n",
    "    mlflow.log_artifact(\"test_artifact.txt\", \"test_artifact\")\n",
    "\n",
    "print(f\"Run id запуска: {run_id}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_metric\n"
     ]
    }
   ],
   "source": [
    "!ls mlflow_experiments_store/0/{run_id}/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_artifact"
     ]
    }
   ],
   "source": [
    "!cat mlflow_experiments_store/0/{run_id}/artifacts/test_artifact/test_artifact.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск с БД sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('http://0.0.0.0:5000')\n",
    "\n",
    "# получаем id эксперимента, который создаётся по умолчанию\n",
    "# эксперимент по умолчанию называется Default\n",
    "experiment_id = mlflow.get_experiment_by_name(\"Default\").experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=\"Default\", experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    mlflow.log_metric(\"test_metric_sqlite\", 0)\n",
    "    mlflow.log_artifact(\"test_artifact.txt\", \"test_artifact_sqlite\")\n",
    "\n",
    "# проверим, что наши данные сохранились в локальной папке, а также создалась база данных SQLite\n",
    "assert os.path.exists(\"mlflow_experiments_store_sqlite\")\n",
    "assert os.path.exists(\"mydb.sqlite\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск с удаленным хранилищем артефактов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определяем основные credentials, которые нужны для подключения к MLflow\n",
    "# важно, что credentials мы передаём для себя как пользователей Tracking Service\n",
    "# у вас должен быть доступ к бакету, в который вы будете складывать артефакты\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" #endpoint бакета от YandexCloud\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\") # получаем id ключа бакета, к которому подключён MLFlow, из .env\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\") # получаем ключ бакета, к которому подключён MLFlow, из .env\n",
    "\n",
    "# определяем глобальные переменные\n",
    "# поднимаем MLflow локально\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "YOUR_NAME = \"alexdem\" # введите своё имя для создания уникального эксперимента\n",
    "assert YOUR_NAME, \"введите своё имя в переменной YOUR_NAME для создания уникального эксперимента\"\n",
    "\n",
    "# название тестового эксперимента и запуска (run) внутри него\n",
    "EXPERIMENT_NAME = f\"test_connection_experiment_{YOUR_NAME}\"\n",
    "RUN_NAME = \"test_connection_run\"\n",
    "\n",
    "# тестовые данные\n",
    "METRIC_NAME = \"test_metric\"\n",
    "METRIC_VALUE = 0\n",
    "\n",
    "# устанавливаем host, который будет отслеживать наши эксперименты\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "\n",
    "# создаём тестовый эксперимент и записываем в него тестовую информацию\n",
    "experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    mlflow.log_metric(METRIC_NAME, METRIC_VALUE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 4. Проверяем себя, что в MLflow:\n",
    "# - создался `experiment` с нашим именем\n",
    "# - внутри эксперимента появился запуск `run`\n",
    "# - внутри `run` записалась наша тестовая `metric`\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "run = mlflow.get_run(run_id)\n",
    "\n",
    "assert \"active\" == experiment.lifecycle_stage\n",
    "assert mlflow.get_run(run_id)\n",
    "assert METRIC_VALUE == run.data.metrics[METRIC_NAME] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выгрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер нашей таблицы: 7043 строк; 22 столбцов\n"
     ]
    }
   ],
   "source": [
    "import psycopg2 as psycopg\n",
    "import pandas as pd\n",
    "\n",
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": os.getenv(\"DESTINATION_HOST\"), \n",
    "    \"port\": \"6432\",\n",
    "    \"dbname\": os.getenv(\"DESTINATION_DB\"),\n",
    "    \"user\": os.getenv(\"DESTINATION_USER\"),\n",
    "    \"password\": os.getenv(\"DESTINATION_PASSWORD\"),\n",
    "}\n",
    "assert all([var_value != \"\" for var_value in list(postgres_credentials.values())])\n",
    "\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "# определяем название таблицы, в которой хранятся наши данные\n",
    "TABLE_NAME = \"users_churn\"\n",
    "\n",
    "\n",
    "# эта конструкция создаёт контекстное управление для соединения с базой данных \n",
    "# оператор with гарантирует, что соединение будет корректно закрыто после выполнения всех операций с базой данных\n",
    "# причём закрыто оно будет даже в случае ошибки при работе с базой данных\n",
    "# это нужно, чтобы не допустить так называемую \"утечку памяти\"\n",
    "with psycopg.connect(**connection) as conn:\n",
    "\n",
    "# создаём объект курсора для выполнения запросов к базе данных \n",
    "# с помощью метода execute() выполняется SQL-запрос для выборки данных из таблицы TABLE_NAME\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "\t\t\t\t\n",
    "\t\t\t\t# извлекаем все строки, полученные в результате выполнения запроса\n",
    "        data = cur.fetchall()\n",
    "\n",
    "\t\t\t\t# получаем список имён столбцов из объекта курсора\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "# создаём объект DataFrame из полученных данных и имён столбцов \n",
    "# это позволяет удобно работать с данными в Python с использованием библиотеки Pandas\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "print(f\"Размер нашей таблицы: {df.shape[0]} строк; {df.shape[1]} столбцов\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определяем основные credentials, которые нужны для подключения к MLflow\n",
    "# важно, что credentials мы передаём для себя как пользователей Tracking Service\n",
    "# у вас должен быть доступ к бакету, в который вы будете складывать артефакты\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" #endpoint бакета от YandexCloud\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\") # получаем id ключа бакета, к которому подключён MLFlow, из .env\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\") # получаем ключ бакета, к которому подключён MLFlow, из .env\n",
    "\n",
    "# определяем глобальные переменные\n",
    "# поднимаем MLflow локально\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.get_experiment_by_name(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"churn_task_alexdem\"\n",
    "RUN_NAME = \"data_check\"\n",
    "\n",
    "experiment_id = mlflow.create_experiment(EXPERIMENT_NAME) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {\"mae\": 2, \"r2\": 0.82}\n",
    "artifact_path = \"dataframe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"columns.txt\", \"w\") as f:\n",
    "    f.write(\",\".join(df.columns))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"users_churn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'experiment_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m RUN_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_check\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# создаём новый эксперимент в MLflow с указанным названием \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# если эксперимент с таким именем уже существует, \u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# MLflow возвращает идентификатор существующего эксперимента\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEXPERIMENT_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment_id\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_id:\n\u001b[1;32m     11\u001b[0m     experiment_id \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mcreate_experiment(EXPERIMENT_NAME) \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'experiment_id'"
     ]
    }
   ],
   "source": [
    "# задаём название эксперимента и имя запуска для логирования в MLflow\n",
    "\n",
    "EXPERIMENT_NAME = \"churn_task_alexdem\"\n",
    "RUN_NAME = \"data_check\"\n",
    "\n",
    "# создаём новый эксперимент в MLflow с указанным названием \n",
    "# если эксперимент с таким именем уже существует, \n",
    "# MLflow возвращает идентификатор существующего эксперимента\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "if not experiment_id:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME) \n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    # получаем уникальный идентификатор запуска эксперимента\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # логируем метрики эксперимента\n",
    "    # предполагается, что переменная stats содержит словарь с метриками,\n",
    "    # где ключи — это названия метрик, а значения — числовые значения метрик\n",
    "    mlflow.log_metrics(stats)\n",
    "    \n",
    "    # логируем файлы как артефакты эксперимента — 'columns.txt' и 'users_churn.csv'\n",
    "    mlflow.log_artifact(\"columns.txt\", artifact_path)\n",
    "    mlflow.log_artifact(\"users_churn.csv\", artifact_path)\n",
    "\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "# получаем данные о запуске эксперимента по его уникальному идентификатору\n",
    "run = mlflow.get_run(run_id)\n",
    "\n",
    "\n",
    "# проверяем, что статус запуска эксперимента изменён на 'FINISHED'\n",
    "# это утверждение (assert) можно использовать для автоматической проверки того, \n",
    "# что эксперимент был завершён успешно\n",
    "assert run.info.status == \"FINISHED\"\n",
    "\n",
    "# удаляем файлы 'columns.txt' и 'users_churn.csv' из файловой системы,\n",
    "# чтобы очистить рабочую среду после логирования артефактов\n",
    "os.remove(\"columns.txt\")\n",
    "os.remove(\"users_churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
